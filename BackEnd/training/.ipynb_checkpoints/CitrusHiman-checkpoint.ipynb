{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"50b117a3-d769-43b8-aa00-3665d60a07b4"},"outputs":[],"source":["fgimport tensorflow as tf\n","from tensorflow.keras import models, layers\n","import matplotlib.pyplot as plt"],"id":"50b117a3-d769-43b8-aa00-3665d60a07b4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"318bd5fa-e98f-47b3-a33b-5f427907b948"},"outputs":[],"source":["IMAGE_SIZE = 800\n","BATCH_SIZE = 32\n","CHANNELS = 3\n","EPOCHS = 50"],"id":"318bd5fa-e98f-47b3-a33b-5f427907b948"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57402,"status":"ok","timestamp":1706887600869,"user":{"displayName":"Avi Singh","userId":"16457266492913206058"},"user_tz":-330},"id":"SAv7X_0BLUIm","outputId":"9f296397-a3e1-4dd3-d47f-b50edd385713"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"SAv7X_0BLUIm"},{"cell_type":"code","execution_count":null,"metadata":{"id":"oHBY5GAyLhZW"},"outputs":[],"source":["dataset_path = '/content/drive/My Drive/Kaggle/dataset'"],"id":"oHBY5GAyLhZW"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5877,"status":"ok","timestamp":1706887606741,"user":{"displayName":"Avi Singh","userId":"16457266492913206058"},"user_tz":-330},"id":"8Pc2zpczNSgV","outputId":"072a9133-7e68-4cfe-b77f-9716905ca2d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.flush_and_unmount()\n","drive.mount('/content/drive')"],"id":"8Pc2zpczNSgV"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1706887606741,"user":{"displayName":"Avi Singh","userId":"16457266492913206058"},"user_tz":-330},"id":"9hYTpF8eNSxo","outputId":"2df4b56f-99af-465f-c9a0-33bd5675d985"},"outputs":[{"output_type":"stream","name":"stdout","text":[" beneficiary.pdf\t\t\t 'MP(Assignment -1,2).pdf'\n","'Cap Id.pdf'\t\t\t\t  OOPLM\n"," Certificates\t\t\t\t 'OS EXp 10 (1) (1)-Copy export.gdoc'\n"," Classroom\t\t\t\t  PCE_REPORT.gdoc\n"," CM-5-REG-IP-NEW.gdoc\t\t\t \"PDF's\"\n"," CN_Exp-3.docx\t\t\t\t  Python_Exp.gdoc\n","'Colab Notebooks'\t\t\t 'PYTHON EXPRIMENT (1).gdoc'\n"," CP\t\t\t\t\t 'PYTHON EXPRIMENT.gdoc'\n"," DWM\t\t\t\t\t  Result\n","'dwm exp9 (1) (1).docx'\t\t\t 'Resume '\n","'Exp1 Report.gdoc'\t\t\t 'Resume (1).gdoc'\n"," exp3_148.docx\t\t\t\t  Resume.gdoc\n"," exp4_148.docx\t\t\t\t  SEA107_EXPT-10.gdoc\n"," exp5_148.docx\t\t\t\t  SEA107_EXPT-1.gdoc\n"," exp6_148.docx\t\t\t\t  SEA107_EXPT-2.gdoc\n"," exp7_148.docx\t\t\t\t  SEA107_EXPT-3.gdoc\n"," exp8_148.docx\t\t\t\t  SEA107_EXPT-4.gdoc\n","'F.E. Result -University of Mumbai.pdf'   SEA107_EXPT-5.gdoc\n"," IMG_20220828_112221.jpg\t\t  SEA107_EXPT-6.gdoc\n"," IMG_20220828_115707.jpg\t\t  SEA107_EXPT-7.gdoc\n"," IMG_20220828_115907.jpg\t\t  SEA107_EXPT-8.gdoc\n"," IMG_20220828_120353.jpg\t\t  SEA107_EXPT-9.gdoc\n"," IMG_20220828_121113.jpg\t\t  SE-Comps_SEM4_M4-CBCGS_MAY18.pdf\n"," IMG_20220828_142851.jpg\t\t 'Semester 4 Logbook (1).pdf'\n"," IMG-20220828-WA0005.jpeg\t\t  TechMax.gdoc\n","'Major project'\t\t\t\t 'Untitled document (1).gdoc'\n"," MARKSHEET.pdf\t\t\t\t 'Untitled document (2).gdoc'\n","'message_1 (1).gdoc'\t\t\t 'Untitled document (3).gdoc'\n"," message_1.gdoc\t\t\t\t 'Untitled document (4).gdoc'\n","'MINIPROJECT LOGBOOK 22.pdf'\t\t 'Untitled document (5).gdoc'\n"," Mini-Project_Reportpdf.pdf\t\t 'Untitled document.gdoc'\n","ls: cannot access '/content/drive/My Drive/Kaggle/': No such file or directory\n"]}],"source":["import os\n","\n","# Check the contents of the current directory in your Google Drive\n","!ls '/content/drive/My Drive/'\n","\n","# Navigate through the directory structure to confirm the existence of 'Dataset/dataset'\n","!ls '/content/drive/My Drive/Kaggle/'\n","\n","# If the directory exists, use the absolute path in your code\n","dataset_path = '/content/drive/My Drive/Dataset/dataset'\n"],"id":"9hYTpF8eNSxo"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"executionInfo":{"elapsed":16,"status":"error","timestamp":1706887606741,"user":{"displayName":"Avi Singh","userId":"16457266492913206058"},"user_tz":-330},"id":"f763af32-1d93-42ba-ad78-3b6677565a72","outputId":"97cb19f1-3ec9-43f7-f260-0fbc1405cfd6"},"outputs":[{"output_type":"error","ename":"NotFoundError","evalue":"Could not find directory /content/drive/MyDrive/KAGGLE/Fruits","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-4ee23bd55adc>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Creating the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m dataset = tf.keras.preprocessing.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;34m'/content/drive/MyDrive/KAGGLE/Fruits'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     image_paths, labels, class_names = dataset_utils.index_directory(\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0msubdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mlist_directory_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    766\u001b[0m   \"\"\"\n\u001b[1;32m    767\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m     raise errors.NotFoundError(\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0mnode_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: Could not find directory /content/drive/MyDrive/KAGGLE/Fruits"]}],"source":["IMAGE_SIZE = (128, 128)  # Define image size as a tuple with height and width\n","\n","# Creating the dataset\n","dataset = tf.keras.preprocessing.image_dataset_from_directory(\n","    '/content/drive/MyDrive/KAGGLE/Fruits',\n","    shuffle=True,\n","    image_size=IMAGE_SIZE,\n","    batch_size=BATCH_SIZE\n",")\n","\n"],"id":"f763af32-1d93-42ba-ad78-3b6677565a72"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2bd18a52-0bd7-48e2-8f0e-02ab156c42b6"},"outputs":[],"source":["class_names = dataset.class_names\n","class_names"],"id":"2bd18a52-0bd7-48e2-8f0e-02ab156c42b6"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ba89409c-64b7-4168-a8ef-bdf8fc7dd4cb"},"outputs":[],"source":["len(dataset)"],"id":"ba89409c-64b7-4168-a8ef-bdf8fc7dd4cb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"99fd3d37-0096-4df1-af57-6789ff88aff1"},"outputs":[],"source":["plt.figure(figsize=(10, 10))\n","for image_batch, label_batch in dataset.take(1):\n","    for i in range(12):\n","       ax = plt.subplot(3,4,i+1)\n","       plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n","       plt.title(class_names[label_batch[i]])\n","       plt.axis(\"off\")"],"id":"99fd3d37-0096-4df1-af57-6789ff88aff1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"52287ed9-8ee4-4c88-9182-9879d56755b2"},"outputs":[],"source":["len(dataset)"],"id":"52287ed9-8ee4-4c88-9182-9879d56755b2"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4bba0518-14c3-449d-a457-db28f250409f"},"outputs":[],"source":["##80% ==> training\n","##20% ==> 10% validation, 10% test"],"id":"4bba0518-14c3-449d-a457-db28f250409f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"24813d37-ef6e-49e8-b96e-d66495fc12b4"},"outputs":[],"source":["train_size = 0.8\n","len(dataset)*train_size"],"id":"24813d37-ef6e-49e8-b96e-d66495fc12b4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0bcbfc10-b266-4630-a396-f1cb6577cb25"},"outputs":[],"source":["train_ds= dataset.take(10)\n","len(train_ds)"],"id":"0bcbfc10-b266-4630-a396-f1cb6577cb25"},{"cell_type":"code","execution_count":null,"metadata":{"id":"adac1a9b-4ad4-40f7-906e-fc0e46a424ea"},"outputs":[],"source":["test_ds = dataset.skip(10)\n","len(test_ds)"],"id":"adac1a9b-4ad4-40f7-906e-fc0e46a424ea"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9eda5788-5b06-478e-a9d5-9b8a85db103f"},"outputs":[],"source":["val_size=0.1\n","len(dataset)*val_size"],"id":"9eda5788-5b06-478e-a9d5-9b8a85db103f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"846aa67f-c6d6-4603-9655-e2a0c24a4db1"},"outputs":[],"source":["val_ds= test_ds.take(7)\n","len(test_ds)"],"id":"846aa67f-c6d6-4603-9655-e2a0c24a4db1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4de51741-4079-41ec-a602-7b936c47891d"},"outputs":[],"source":["test_ds = dataset.skip(3)\n","len(test_ds)"],"id":"4de51741-4079-41ec-a602-7b936c47891d"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9b79b93a-2907-4251-9029-7bf8b2616018"},"outputs":[],"source":["def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split = 0.1, shuffle=True, shuffle_size=1000):\n","    ds_size = len(ds)\n","\n","    if shuffle:\n","        ds = ds.shuffle(shuffle_size,seed=12)\n","\n","    train_size = int(train_split * ds_size)\n","    val_size = int(val_split * ds_size)\n","\n","    train_ds = ds.take(train_size)\n","\n","    val_ds = ds.skip(train_size).take(val_size)\n","    test_ds = ds.skip(train_size).skip(val_size)\n","\n","    return train_ds, val_ds, test_ds"],"id":"9b79b93a-2907-4251-9029-7bf8b2616018"},{"cell_type":"code","execution_count":null,"metadata":{"id":"91d6dd16-11b7-418c-9811-96bbd1137065"},"outputs":[],"source":["train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)"],"id":"91d6dd16-11b7-418c-9811-96bbd1137065"},{"cell_type":"code","execution_count":null,"metadata":{"id":"7371c4a5-9813-4e1e-8951-7a77971b3160"},"outputs":[],"source":["len(train_ds)"],"id":"7371c4a5-9813-4e1e-8951-7a77971b3160"},{"cell_type":"code","execution_count":null,"metadata":{"id":"cadf801d-2dea-4c8f-b308-27dcd052bc88"},"outputs":[],"source":["len(val_ds)"],"id":"cadf801d-2dea-4c8f-b308-27dcd052bc88"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5c03e041-f482-43da-9b28-e043564a3ec5"},"outputs":[],"source":["len(test_ds)"],"id":"5c03e041-f482-43da-9b28-e043564a3ec5"},{"cell_type":"code","execution_count":null,"metadata":{"id":"87122c2a-209a-44e7-8628-6e161ff79469"},"outputs":[],"source":["train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n","val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n","test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"],"id":"87122c2a-209a-44e7-8628-6e161ff79469"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ed29ec4c-6d4d-4e91-ae8e-a48f01d84b89"},"outputs":[],"source":["resize_and_rescale = tf.keras.Sequential([\n","    layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n","    layers.experimental.preprocessing.Rescaling(1.0/255)\n","    ])"],"id":"ed29ec4c-6d4d-4e91-ae8e-a48f01d84b89"},{"cell_type":"code","execution_count":null,"metadata":{"id":"430fc982-fb18-4ee7-b48b-f261b204a9c2"},"outputs":[],"source":["data_augmentation= tf.keras.Sequential([\n","    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n","    layers.experimental.preprocessing.RandomRotation(0.2)\n","])"],"id":"430fc982-fb18-4ee7-b48b-f261b204a9c2"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a3060d93-a591-44ce-8037-cf283f178df6"},"outputs":[],"source":["from tensorflow.keras import layers, models\n","\n","input_shape = (128, 128, 3)  # Adjusted input shape assuming 128x128 RGB images\n","n_classes = 5\n","\n","model = models.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),  # Additional Conv2D layer\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),  # Additional Conv2D layer\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),  # Additional Dense layer\n","    layers.Dense(64, activation='relu'),\n","    layers.Dense(n_classes, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Display model summary\n","model.summary()\n"],"id":"a3060d93-a591-44ce-8037-cf283f178df6"},{"cell_type":"code","execution_count":null,"metadata":{"id":"151fef07-89da-422b-a205-b05d0d21f08a"},"outputs":[],"source":["model.summary()"],"id":"151fef07-89da-422b-a205-b05d0d21f08a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ecc65ef8-4e2f-44fd-8946-c800bced6a50"},"outputs":[],"source":["model.compile(\n","    optimizer= 'adam',\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n","    metrics=['accuracy']\n",")"],"id":"ecc65ef8-4e2f-44fd-8946-c800bced6a50"},{"cell_type":"code","execution_count":null,"metadata":{"id":"99e01fcb-2cde-48e7-bf10-a159af2be1b4"},"outputs":[],"source":["history = model.fit(\n","    train_ds,\n","    epochs=EPOCHS,\n","    batch_size=BATCH_SIZE,\n","    verbose=2,\n","    validation_data=val_ds\n",")"],"id":"99e01fcb-2cde-48e7-bf10-a159af2be1b4"},{"cell_type":"code","source":["# Define your RL exploration function\n","def explore_exploit(model, dataset, epsilon=0.1):\n","    for images, labels in dataset:\n","        batch_size = len(images)\n","        for i in range(batch_size):\n","            if np.random.rand() < epsilon:\n","                # Explore: Randomly choose an action (in this case, select a random image)\n","                rand_index = np.random.randint(0, batch_size)\n","                image = images[rand_index]\n","            else:\n","                # Exploit: Use the model to predict and choose the best action (image)\n","                predictions = model.predict(images)\n","                image = images[np.argmax(predictions)]\n","\n","            # Train the model on the selected image\n","            model.train_on_batch(np.expand_dims(image, axis=0), np.array([labels[i]]))"],"metadata":{"id":"kKrJMo1qEvLt"},"id":"kKrJMo1qEvLt","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"56e2579a-af6c-41a9-a242-202c84e031bd"},"outputs":[],"source":["scores = model.evaluate(test_ds)"],"id":"56e2579a-af6c-41a9-a242-202c84e031bd"},{"cell_type":"code","execution_count":null,"metadata":{"id":"165348a3-627a-497e-a58b-79a51d53a36a"},"outputs":[],"source":["scores"],"id":"165348a3-627a-497e-a58b-79a51d53a36a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"f3b3dae1-8eec-4a7f-9761-f2d36e7f6556"},"outputs":[],"source":["history"],"id":"f3b3dae1-8eec-4a7f-9761-f2d36e7f6556"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e1736d37-e2e8-48a3-b7e8-d7b540a8f4e8"},"outputs":[],"source":["history.params"],"id":"e1736d37-e2e8-48a3-b7e8-d7b540a8f4e8"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a13b9360-0ac8-4f25-a7df-d31a768c5546"},"outputs":[],"source":["history.history.keys()"],"id":"a13b9360-0ac8-4f25-a7df-d31a768c5546"},{"cell_type":"code","execution_count":null,"metadata":{"id":"aee2d9e2-25fa-49de-9203-0de01e3eb50a"},"outputs":[],"source":["history.history['accuracy']"],"id":"aee2d9e2-25fa-49de-9203-0de01e3eb50a"},{"cell_type":"code","source":["# Evaluate the model's performance after RL\n","test_accuracy = model.evaluate(test_ds)[1]  # Assuming accuracy is at index 1\n","\n","print(\"Test Accuracy after RL:\", test_accuracy)"],"metadata":{"id":"wFBPvAlTE726"},"id":"wFBPvAlTE726","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1de44672-1838-408e-b289-b5257c82be3b"},"outputs":[],"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']"],"id":"1de44672-1838-408e-b289-b5257c82be3b"},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(12, 6))\n","\n","# Subplot 1 (top left)\n","plt.subplot(1, 2, 1)\n","plt.plot(range(EPOCHS), acc, label='Training Accuracy')\n","plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","# Subplot 2 (top right)\n","plt.subplot(1, 2, 2)\n","plt.plot(range(EPOCHS), loss, label='Training Loss')\n","plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","\n","plt.tight_layout()  # Adjusts subplot parameters to fit the figure area properly\n","plt.show()\n"],"metadata":{"id":"BNe_qJjNyWUz"},"id":"BNe_qJjNyWUz","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Assuming 'class_names' is a list of class labels\n","\n","for images_batch, labels_batch in test_ds.take(1):\n","    first_image = images_batch[0].numpy().astype('uint8')  # Fix typo 'uint9' to 'uint8'\n","    first_label = labels_batch[0].numpy()\n","\n","    print(\"First image to predict\")\n","    plt.imshow(first_image)\n","    plt.title(\"First image\")\n","    plt.show()\n","\n","    print(\"First image's actual label:\", class_names[first_label])\n","\n","    batch_prediction = model.predict(images_batch)\n","    predicted_label = np.argmax(batch_prediction[0])\n","    print(\"Predicted label:\", class_names[predicted_label])\n"],"metadata":{"id":"W3IMapPry0Dy"},"id":"W3IMapPry0Dy","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict(model, img):\n","    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n","    img_array = tf.expand_dims(img_array,0) # Create a batch\n","\n","    predictions = model.predict(img_array)\n","\n","    predicted_class = class_names[np.argmax(predictions[0])]\n","    confidence = round(100 * (np.max(predictions[0])), 2)\n","    return predicted_class, confidence"],"metadata":{"id":"b6AKf1yBvqVI"},"id":"b6AKf1yBvqVI","execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(15, 15))\n","for images, labels in test_ds.take(1):\n","    for i in range(9):\n","        ax = plt.subplot(3, 3, i + 1)\n","        plt.imshow(images[i].numpy().astype(\"uint8\"))\n","\n","        predicted_class, confidence = predict(model, images[i].numpy())\n","        actual_class = class_names[labels[i]]\n","\n","        plt.title(f\"Actual: {actual_class},\\nPredicted: {predicted_class}.\\nConfidence: {confidence:.2f}%\")\n","\n","        plt.axis(\"off\")\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"k616p2GCzEHE"},"id":"k616p2GCzEHE","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v_geFzaq-8Kn"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Example data (replace these with your actual data)\n","epochs = range(50)  # Assuming 50 epochs\n","\n","# Example accuracy and loss values for demonstration (replace these with your actual data)\n","train_accuracy = [0.5, 0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.92, 0.93, 0.94,\n","                  0.945, 0.95, 0.952, 0.955, 0.957, 0.959, 0.961, 0.963,\n","                  0.965, 0.966, 0.967, 0.968, 0.969, 0.97, 0.971, 0.972,\n","                  0.973, 0.974, 0.975, 0.976, 0.977, 0.978, 0.979, 0.98,\n","                  0.981, 0.982, 0.983, 0.984, 0.985, 0.986, 0.987, 0.988,\n","                  0.989, 0.99, 0.991, 0.992, 0.993, 0.994, 0.995, 0.996]  # Training accuracy values for each epoch (should have 50 elements)\n","\n","val_accuracy = [0.4, 0.55, 0.65, 0.7, 0.72, 0.74, 0.75, 0.76, 0.77, 0.775,\n","                0.78, 0.782, 0.784, 0.786, 0.788, 0.79, 0.791, 0.792,\n","                0.793, 0.794, 0.795, 0.796, 0.797, 0.798, 0.799, 0.8,\n","                0.801, 0.802, 0.803, 0.804, 0.805, 0.806, 0.807, 0.808,\n","                0.809, 0.81, 0.811, 0.812, 0.813, 0.814, 0.815, 0.816,\n","                0.817, 0.818, 0.819, 0.82, 0.821, 0.822, 0.823, 0.824,\n","                0.825, 0.826]  # Validation accuracy values for each epoch (should have 50 elements)\n","\n","train_loss = [1.2, 0.9, 0.7, 0.6, 0.55, 0.52, 0.5, 0.48, 0.45, 0.43,\n","              0.42, 0.41, 0.4, 0.39, 0.38, 0.37, 0.36, 0.35, 0.34,\n","              0.33, 0.32, 0.31, 0.3, 0.29, 0.28, 0.27, 0.26, 0.25,\n","              0.24, 0.23, 0.22, 0.21, 0.2, 0.19, 0.18, 0.17, 0.16,\n","              0.15, 0.14, 0.13, 0.12, 0.11, 0.1, 0.09, 0.08, 0.07,\n","              0.06, 0.05, 0.04, 0.03, 0.02, 0.01]  # Training loss values for each epoch (should have 50 elements)\n","\n","val_loss = [1.5, 1.0, 0.8, 0.7, 0.65, 0.62, 0.6, 0.58, 0.55, 0.53,\n","            0.52, 0.51, 0.5, 0.49, 0.48, 0.47, 0.46, 0.45, 0.44,\n","            0.43, 0.42, 0.41, 0.4, 0.39, 0.38, 0.37, 0.36, 0.35,\n","            0.34, 0.33, 0.32, 0.31, 0.3, 0.29, 0.28, 0.27, 0.26,\n","            0.25, 0.24, 0.23, 0.22, 0.21, 0.2, 0.19, 0.18, 0.17,\n","            0.16]\n"],"id":"v_geFzaq-8Kn"},{"cell_type":"code","execution_count":null,"metadata":{"id":"004ccb17-669f-4374-a087-d5f57d829faa"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","for images_batch, labels_batch in test_ds.take(1):\n","    first_image = images_batch[0].numpy().astype('uint8')  # Corrected the typo in 'uint8'\n","    first_label = labels_batch[0].numpy()\n","\n","    print(\"First image to predict:\")\n","    plt.imshow(first_image)\n","    plt.show()\n","    print(\"First image's actual label:\", class_names[first_label])\n","\n","    batch_prediction = model.predict(images_batch)\n","    print(\"Predicted label:\", class_names[np.argmax(batch_prediction[0])])\n"],"id":"004ccb17-669f-4374-a087-d5f57d829faa"},{"cell_type":"code","execution_count":null,"metadata":{"id":"dca6324b-814f-49c4-be48-30e21bd9f00c"},"outputs":[],"source":["def predict(model, img):\n","    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n","    img_array = tf.expand_dims(img_array,0) # Create a batch\n","\n","    predictions = model.predict(img_array)\n","\n","    predicted_class = class_names[np.argmax(predictions[0])]\n","    confidence = round(100 * (np.max(predictions[0])), 2)\n","    return predicted_class, confidence"],"id":"dca6324b-814f-49c4-be48-30e21bd9f00c"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3eb9d718-53ac-4f68-ac21-c5b4b1657dfe"},"outputs":[],"source":["model_version=1\n","model.save(f\"../models/{model_version}\")"],"id":"3eb9d718-53ac-4f68-ac21-c5b4b1657dfe"},{"cell_type":"code","execution_count":null,"metadata":{"id":"66a12fcd-396c-47ac-b9be-bf9912dbe6f9"},"outputs":[],"source":["#string to imnteger\n","import os\n","model_version=max([int(i) for i in os.listdir(\"../models\") + [0]]) + 1\n","model.save(f\"../models/{model_version}\")"],"id":"66a12fcd-396c-47ac-b9be-bf9912dbe6f9"}],"metadata":{"colab":{"provenance":[{"file_id":"149f9PHSznscps2HdLDlEge0qKs2YW48h","timestamp":1706887322690}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":5}